{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm.notebook import tqdm  # Use notebook version for Jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder containing the raw dataset files\n",
    "raw_data_folder = \"raw dataset\"  # Update with your actual folder path\n",
    "\n",
    "# Get all file names in the folder\n",
    "all_files = sorted([f for f in os.listdir(raw_data_folder) if f.endswith(\".csv\")])\n",
    "\n",
    "# Identify signal and background files\n",
    "signal_file = [f for f in all_files if \"signal\" in f.lower()][0]  # Assumes \"signal\" is in filename\n",
    "background_files = sorted([f for f in all_files if \"B\" in f.upper()])  # Assumes \"B\" in filename means background\n",
    "\n",
    "# # Load the signal dataset and add a label column\n",
    "# signal_df = pd.read_csv(os.path.join(raw_data_folder, signal_file))\n",
    "# signal_df[\"label\"] = 1  # Assign label 1 for signal events\n",
    "\n",
    "# # Load background datasets and add a label column\n",
    "# background_dfs = []\n",
    "background_labels = []  # Store filenames for indexing reference\n",
    "\n",
    "for idx, bg_file in enumerate(background_files):\n",
    "    bg_df = pd.read_csv(os.path.join(raw_data_folder, bg_file))\n",
    "    # bg_df[\"label\"] = 0  # Assign label 0 for background events\n",
    "    # background_dfs.append(bg_df)\n",
    "    background_labels.append(bg_file)  # Store file name for reference\n",
    "    # print(f\"Background {idx}: {bg_file}\")  # Print index and file name\n",
    "\n",
    "# # Extract features (X) and labels (y)\n",
    "# X_signal = signal_df.iloc[:, :-1]  # Features for signal\n",
    "# y_signal = signal_df.iloc[:, -1]   # Labels for signal\n",
    "\n",
    "# X_backgrounds = [bg.iloc[:, :-1] for bg in background_dfs]  # Features for each background dataset\n",
    "# y_backgrounds = [bg.iloc[:, -1] for bg in background_dfs]  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBoost Training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccf1e92dbcc4ee0a71a1610e488606c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/12 [00:00<?, ?model/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1/12 trained on BWW.csv (Time: 0.64 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2/12 trained on BZH.csv (Time: 0.87 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3/12 trained on BZZ.csv (Time: 0.70 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4/12 trained on Bpebb.csv (Time: 0.75 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5/12 trained on Bpebbqq.csv (Time: 0.68 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6/12 trained on BpeqqH.csv (Time: 0.87 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7/12 trained on Bpett.csv (Time: 0.72 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8/12 trained on Bqq.csv (Time: 0.96 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9/12 trained on BqqHX.csv (Time: 0.86 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10/12 trained on BqqX.csv (Time: 0.68 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 11/12 trained on BqqqqX.csv (Time: 0.65 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 12/12 trained on Btt.csv (Time: 0.60 sec)\n",
      "\n",
      "Training Complete! All models are ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "depth = 2\n",
    "n = 100\n",
    "lr = 0.1\n",
    "\n",
    "# Store trained models and test sets\n",
    "trained_xgb_models = []\n",
    "train_test_splits = []\n",
    "\n",
    "# Load signal training data\n",
    "X_train_signal = joblib.load('split_datasets/X_train_signal.pkl')\n",
    "y_train_signal = joblib.load('split_datasets/y_train_signal.pkl')\n",
    "\n",
    "print(\"\\nStarting XGBoost Training...\\n\")\n",
    "\n",
    "# Initialize tqdm progress bar\n",
    "with tqdm(total=12, desc=\"Training Progress\", unit=\"model\", leave=True) as pbar:\n",
    "    for i in range(12):\n",
    "        start_time = time.time()  # Track time for each model\n",
    "\n",
    "        # Clean filename for loading\n",
    "        clean_name = background_labels[i].replace('.csv', '').replace(' ', '_')\n",
    "        \n",
    "        # Load background training data\n",
    "        X_train_bg = joblib.load(f'split_datasets/X_train_{clean_name}.pkl')\n",
    "        y_train_bg = joblib.load(f'split_datasets/y_train_{clean_name}.pkl')\n",
    "        # X_test_bg = joblib.load(f'split_datasets/X_test_{clean_name}.pkl')\n",
    "        # y_test_bg = joblib.load(f'split_datasets/y_test_{clean_name}.pkl')\n",
    "\n",
    "        # Combine signal + one background dataset\n",
    "        X_train_combined = pd.concat([X_train_signal, X_train_bg])\n",
    "        y_train_combined = np.concatenate([y_train_signal, y_train_bg])\n",
    "\n",
    "        # Split into train (75%) and test (25%)\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.25, random_state=42)\n",
    "\n",
    "        # Convert to XGBoost DMatrix (optimized for speed)\n",
    "        dtrain = xgb.DMatrix(X_train_combined, label=y_train_combined)\n",
    "        # dtest = xgb.DMatrix(X_test_, label=y_test)\n",
    "\n",
    "        # Define XGBoost parameters\n",
    "        xgb_params = {\n",
    "            \"objective\": \"binary:logistic\",  # Binary classification\n",
    "            \"eval_metric\": \"logloss\",  # Log-loss for binary classification\n",
    "            \"max_depth\": depth,  # Similar to BDT depth\n",
    "            \"learning_rate\": lr,  # Step size\n",
    "            \"n_estimators\": n,  # Number of boosting rounds\n",
    "            \"tree_method\": \"hist\",  # Optimized for speed\n",
    "        }\n",
    "\n",
    "        # Train XGBoost model\n",
    "        xgb_model = xgb.train(params=xgb_params, dtrain=dtrain, num_boost_round=100)\n",
    "\n",
    "        # Store trained model and test data\n",
    "        trained_xgb_models.append(xgb_model)\n",
    "        # train_test_splits.append((X_test, y_test))\n",
    "\n",
    "        # Print progress without interfering with tqdm\n",
    "        elapsed_time = time.time() - start_time\n",
    "        tqdm.write(f\"Model {i+1}/12 trained on {background_labels[i]} (Time: {elapsed_time:.2f} sec)\")\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "print(\"\\nTraining Complete! All models are ready.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 saved to xgb_models/xgb_model_bg1_depth2_n100_lr0.1.model\n",
      "Model 2 saved to xgb_models/xgb_model_bg2_depth2_n100_lr0.1.model\n",
      "Model 3 saved to xgb_models/xgb_model_bg3_depth2_n100_lr0.1.model\n",
      "Model 4 saved to xgb_models/xgb_model_bg4_depth2_n100_lr0.1.model\n",
      "Model 5 saved to xgb_models/xgb_model_bg5_depth2_n100_lr0.1.model\n",
      "Model 6 saved to xgb_models/xgb_model_bg6_depth2_n100_lr0.1.model\n",
      "Model 7 saved to xgb_models/xgb_model_bg7_depth2_n100_lr0.1.model\n",
      "Model 8 saved to xgb_models/xgb_model_bg8_depth2_n100_lr0.1.model\n",
      "Model 9 saved to xgb_models/xgb_model_bg9_depth2_n100_lr0.1.model\n",
      "Model 10 saved to xgb_models/xgb_model_bg10_depth2_n100_lr0.1.model\n",
      "Model 11 saved to xgb_models/xgb_model_bg11_depth2_n100_lr0.1.model\n",
      "Model 12 saved to xgb_models/xgb_model_bg12_depth2_n100_lr0.1.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:20] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the folder to save models\n",
    "model_dir = \"xgb_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Save each trained XGBoost model\n",
    "for i, model in enumerate(trained_xgb_models):\n",
    "    filename = f\"xgb_model_bg{i+1}_depth{depth}_n{n}_lr{lr}.model\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "    model.save_model(filepath)\n",
    "    print(f\"Model {i+1} saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal Test</th>\n",
       "      <th>Background 1 Test</th>\n",
       "      <th>Background 2 Test</th>\n",
       "      <th>Background 3 Test</th>\n",
       "      <th>Background 4 Test</th>\n",
       "      <th>Background 5 Test</th>\n",
       "      <th>Background 6 Test</th>\n",
       "      <th>Background 7 Test</th>\n",
       "      <th>Background 8 Test</th>\n",
       "      <th>Background 9 Test</th>\n",
       "      <th>Background 10 Test</th>\n",
       "      <th>Background 11 Test</th>\n",
       "      <th>Background 12 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>0.993409</td>\n",
       "      <td>0.486408</td>\n",
       "      <td>0.975552</td>\n",
       "      <td>0.914625</td>\n",
       "      <td>0.819303</td>\n",
       "      <td>0.975878</td>\n",
       "      <td>0.992067</td>\n",
       "      <td>0.976934</td>\n",
       "      <td>0.575091</td>\n",
       "      <td>0.988096</td>\n",
       "      <td>0.809345</td>\n",
       "      <td>0.967928</td>\n",
       "      <td>0.966737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>0.802685</td>\n",
       "      <td>0.394110</td>\n",
       "      <td>0.387245</td>\n",
       "      <td>0.326103</td>\n",
       "      <td>0.341408</td>\n",
       "      <td>0.517370</td>\n",
       "      <td>0.692131</td>\n",
       "      <td>0.656223</td>\n",
       "      <td>0.466731</td>\n",
       "      <td>0.690390</td>\n",
       "      <td>0.359923</td>\n",
       "      <td>0.555711</td>\n",
       "      <td>0.826447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>0.906257</td>\n",
       "      <td>0.411589</td>\n",
       "      <td>0.686774</td>\n",
       "      <td>0.315371</td>\n",
       "      <td>0.308418</td>\n",
       "      <td>0.537459</td>\n",
       "      <td>0.757065</td>\n",
       "      <td>0.746431</td>\n",
       "      <td>0.506697</td>\n",
       "      <td>0.752536</td>\n",
       "      <td>0.313584</td>\n",
       "      <td>0.617498</td>\n",
       "      <td>0.953453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 4</th>\n",
       "      <td>0.957887</td>\n",
       "      <td>0.715824</td>\n",
       "      <td>0.887123</td>\n",
       "      <td>0.712968</td>\n",
       "      <td>0.147485</td>\n",
       "      <td>0.659394</td>\n",
       "      <td>0.776503</td>\n",
       "      <td>0.780099</td>\n",
       "      <td>0.657704</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>0.212282</td>\n",
       "      <td>0.784424</td>\n",
       "      <td>0.975413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 5</th>\n",
       "      <td>0.906087</td>\n",
       "      <td>0.688550</td>\n",
       "      <td>0.800367</td>\n",
       "      <td>0.624372</td>\n",
       "      <td>0.312735</td>\n",
       "      <td>0.248639</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.571715</td>\n",
       "      <td>0.726837</td>\n",
       "      <td>0.688594</td>\n",
       "      <td>0.522142</td>\n",
       "      <td>0.659355</td>\n",
       "      <td>0.912911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 6</th>\n",
       "      <td>0.876353</td>\n",
       "      <td>0.736722</td>\n",
       "      <td>0.809523</td>\n",
       "      <td>0.686953</td>\n",
       "      <td>0.323358</td>\n",
       "      <td>0.244592</td>\n",
       "      <td>0.278215</td>\n",
       "      <td>0.489057</td>\n",
       "      <td>0.783427</td>\n",
       "      <td>0.639192</td>\n",
       "      <td>0.539900</td>\n",
       "      <td>0.651393</td>\n",
       "      <td>0.867412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 7</th>\n",
       "      <td>0.972122</td>\n",
       "      <td>0.922036</td>\n",
       "      <td>0.951148</td>\n",
       "      <td>0.946626</td>\n",
       "      <td>0.885136</td>\n",
       "      <td>0.928268</td>\n",
       "      <td>0.928325</td>\n",
       "      <td>0.506853</td>\n",
       "      <td>0.940202</td>\n",
       "      <td>0.890921</td>\n",
       "      <td>0.916063</td>\n",
       "      <td>0.865407</td>\n",
       "      <td>0.687261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 8</th>\n",
       "      <td>0.926772</td>\n",
       "      <td>0.182550</td>\n",
       "      <td>0.861391</td>\n",
       "      <td>0.734916</td>\n",
       "      <td>0.423933</td>\n",
       "      <td>0.888514</td>\n",
       "      <td>0.940293</td>\n",
       "      <td>0.862564</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.915685</td>\n",
       "      <td>0.385749</td>\n",
       "      <td>0.858085</td>\n",
       "      <td>0.261355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 9</th>\n",
       "      <td>0.740123</td>\n",
       "      <td>0.624049</td>\n",
       "      <td>0.679108</td>\n",
       "      <td>0.519131</td>\n",
       "      <td>0.307153</td>\n",
       "      <td>0.289470</td>\n",
       "      <td>0.336098</td>\n",
       "      <td>0.453179</td>\n",
       "      <td>0.678544</td>\n",
       "      <td>0.332121</td>\n",
       "      <td>0.330982</td>\n",
       "      <td>0.344116</td>\n",
       "      <td>0.837742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 10</th>\n",
       "      <td>0.979376</td>\n",
       "      <td>0.805793</td>\n",
       "      <td>0.933545</td>\n",
       "      <td>0.808098</td>\n",
       "      <td>0.251920</td>\n",
       "      <td>0.862323</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.895942</td>\n",
       "      <td>0.743812</td>\n",
       "      <td>0.924177</td>\n",
       "      <td>0.251315</td>\n",
       "      <td>0.874349</td>\n",
       "      <td>0.992957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 11</th>\n",
       "      <td>0.989639</td>\n",
       "      <td>0.954076</td>\n",
       "      <td>0.961733</td>\n",
       "      <td>0.913062</td>\n",
       "      <td>0.861088</td>\n",
       "      <td>0.906434</td>\n",
       "      <td>0.954592</td>\n",
       "      <td>0.837864</td>\n",
       "      <td>0.961534</td>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.864448</td>\n",
       "      <td>0.883378</td>\n",
       "      <td>0.995064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 12</th>\n",
       "      <td>0.994911</td>\n",
       "      <td>0.893139</td>\n",
       "      <td>0.996858</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>0.997505</td>\n",
       "      <td>0.961718</td>\n",
       "      <td>0.857281</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.203891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Signal Test  Background 1 Test  Background 2 Test  \\\n",
       "Model 1      0.993409           0.486408           0.975552   \n",
       "Model 2      0.802685           0.394110           0.387245   \n",
       "Model 3      0.906257           0.411589           0.686774   \n",
       "Model 4      0.957887           0.715824           0.887123   \n",
       "Model 5      0.906087           0.688550           0.800367   \n",
       "Model 6      0.876353           0.736722           0.809523   \n",
       "Model 7      0.972122           0.922036           0.951148   \n",
       "Model 8      0.926772           0.182550           0.861391   \n",
       "Model 9      0.740123           0.624049           0.679108   \n",
       "Model 10     0.979376           0.805793           0.933545   \n",
       "Model 11     0.989639           0.954076           0.961733   \n",
       "Model 12     0.994911           0.893139           0.996858   \n",
       "\n",
       "          Background 3 Test  Background 4 Test  Background 5 Test  \\\n",
       "Model 1            0.914625           0.819303           0.975878   \n",
       "Model 2            0.326103           0.341408           0.517370   \n",
       "Model 3            0.315371           0.308418           0.537459   \n",
       "Model 4            0.712968           0.147485           0.659394   \n",
       "Model 5            0.624372           0.312735           0.248639   \n",
       "Model 6            0.686953           0.323358           0.244592   \n",
       "Model 7            0.946626           0.885136           0.928268   \n",
       "Model 8            0.734916           0.423933           0.888514   \n",
       "Model 9            0.519131           0.307153           0.289470   \n",
       "Model 10           0.808098           0.251920           0.862323   \n",
       "Model 11           0.913062           0.861088           0.906434   \n",
       "Model 12           0.998329           0.998875           0.998040   \n",
       "\n",
       "          Background 6 Test  Background 7 Test  Background 8 Test  \\\n",
       "Model 1            0.992067           0.976934           0.575091   \n",
       "Model 2            0.692131           0.656223           0.466731   \n",
       "Model 3            0.757065           0.746431           0.506697   \n",
       "Model 4            0.776503           0.780099           0.657704   \n",
       "Model 5            0.376321           0.571715           0.726837   \n",
       "Model 6            0.278215           0.489057           0.783427   \n",
       "Model 7            0.928325           0.506853           0.940202   \n",
       "Model 8            0.940293           0.862564           0.118182   \n",
       "Model 9            0.336098           0.453179           0.678544   \n",
       "Model 10           0.937322           0.895942           0.743812   \n",
       "Model 11           0.954592           0.837864           0.961534   \n",
       "Model 12           0.997505           0.961718           0.857281   \n",
       "\n",
       "          Background 9 Test  Background 10 Test  Background 11 Test  \\\n",
       "Model 1            0.988096            0.809345            0.967928   \n",
       "Model 2            0.690390            0.359923            0.555711   \n",
       "Model 3            0.752536            0.313584            0.617498   \n",
       "Model 4            0.839312            0.212282            0.784424   \n",
       "Model 5            0.688594            0.522142            0.659355   \n",
       "Model 6            0.639192            0.539900            0.651393   \n",
       "Model 7            0.890921            0.916063            0.865407   \n",
       "Model 8            0.915685            0.385749            0.858085   \n",
       "Model 9            0.332121            0.330982            0.344116   \n",
       "Model 10           0.924177            0.251315            0.874349   \n",
       "Model 11           0.924283            0.864448            0.883378   \n",
       "Model 12           0.997454            0.998832            0.997021   \n",
       "\n",
       "          Background 12 Test  \n",
       "Model 1             0.966737  \n",
       "Model 2             0.826447  \n",
       "Model 3             0.953453  \n",
       "Model 4             0.975413  \n",
       "Model 5             0.912911  \n",
       "Model 6             0.867412  \n",
       "Model 7             0.687261  \n",
       "Model 8             0.261355  \n",
       "Model 9             0.837742  \n",
       "Model 10            0.992957  \n",
       "Model 11            0.995064  \n",
       "Model 12            0.203891  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load signal test data\n",
    "X_test_signal = joblib.load('split_datasets/X_test_signal.pkl')\n",
    "y_test_signal = joblib.load('split_datasets/y_test_signal.pkl')\n",
    "\n",
    "# Load background test datasets\n",
    "X_test_backgrounds = []\n",
    "y_test_backgrounds = []\n",
    "\n",
    "for bg_file in background_labels:\n",
    "    clean_name = bg_file.replace('.csv', '').replace(' ', '_')\n",
    "    X_test_bg = joblib.load(f'split_datasets/X_test_{clean_name}.pkl')\n",
    "    y_test_bg = joblib.load(f'split_datasets/y_test_{clean_name}.pkl')\n",
    "    \n",
    "    X_test_backgrounds.append(X_test_bg)\n",
    "    y_test_backgrounds.append(y_test_bg)\n",
    "\n",
    "# Initialize a 12x13 matrix to store results\n",
    "output_matrix = np.zeros((12, 13))\n",
    "\n",
    "# Evaluate each trained XGBoost model on the test datasets\n",
    "for model_idx, model in enumerate(trained_xgb_models):\n",
    "    for dataset_idx, dataset in enumerate([X_test_signal] + X_test_backgrounds):  \n",
    "        # Convert dataset to XGBoost DMatrix (necessary for prediction)\n",
    "        dmatrix = xgb.DMatrix(dataset)\n",
    "        \n",
    "        # Get predicted probability (XGBoost automatically returns probabilities for binary classification)\n",
    "        predictions = model.predict(dmatrix)\n",
    "        \n",
    "        # Store the average probability of being signal on **test dataset only**\n",
    "        output_matrix[model_idx, dataset_idx] = np.mean(predictions)  # Mean probability\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "datasets = [\"Signal Test\"] + [f\"Background {i+1} Test\" for i in range(12)]\n",
    "model_labels = [f\"Model {i+1}\" for i in range(12)]\n",
    "\n",
    "df_results = pd.DataFrame(output_matrix, index=model_labels, columns=datasets)\n",
    "\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
