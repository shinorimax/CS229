{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm.notebook import tqdm  # Use notebook version for Jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder containing the raw dataset files\n",
    "raw_data_folder = \"raw dataset\"  # Update with your actual folder path\n",
    "\n",
    "# Get all file names in the folder\n",
    "all_files = sorted([f for f in os.listdir(raw_data_folder) if f.endswith(\".csv\")])\n",
    "\n",
    "# Identify signal and background files\n",
    "signal_file = [f for f in all_files if \"signal\" in f.lower()][0]  # Assumes \"signal\" is in filename\n",
    "background_files = sorted([f for f in all_files if \"B\" in f.upper()])  # Assumes \"B\" in filename means background\n",
    "\n",
    "# Load the signal dataset and add a label column\n",
    "signal_df = pd.read_csv(os.path.join(raw_data_folder, signal_file))\n",
    "# Drop 'nParticles' if it exists\n",
    "if 'nParticles' in signal_df.columns:\n",
    "    signal_df.drop(columns=['nParticles'], inplace=True)\n",
    "signal_df[\"label\"] = 1  # Assign label 1 for signal events\n",
    "\n",
    "# Load background datasets and add a label column\n",
    "background_dfs = []\n",
    "background_labels = []  # Store filenames for indexing reference\n",
    "background_types = []  # Store background type\n",
    "\n",
    "# Define weights for each background type\n",
    "background_weights = {\n",
    "    \"HH\": 0.0015552 * 1.155,\n",
    "    \"qq\": 0.0349,\n",
    "    \"ttbar\": 0.503,\n",
    "    \"ZZ\": 0.17088 * 1.155,\n",
    "    \"WW\": 0.5149,\n",
    "    \"qqX\": 0.04347826,\n",
    "    \"qqqqX\": 0.04,\n",
    "    \"qqHX\": 0.001,\n",
    "    \"ZH\": 0.00207445 * 1.155,\n",
    "    \"pebb\": 0.7536,\n",
    "    \"pebbqq\": 0.1522,\n",
    "    \"peqqH\": 0.1237,\n",
    "    \"pett\": 0.0570,\n",
    "}\n",
    "\n",
    "# Apply reweighting factor for the test set\n",
    "test_size = 0.25\n",
    "reweight_factor = 1 / test_size  # = 4.0\n",
    "background_weights = {k: v * reweight_factor for k, v in background_weights.items()}\n",
    "\n",
    "for idx, bg_file in enumerate(background_files):\n",
    "    bg_df = pd.read_csv(os.path.join(raw_data_folder, bg_file))\n",
    "\n",
    "    # Drop 'nParticles' if it exists\n",
    "    if 'nParticles' in bg_df.columns:\n",
    "        bg_df.drop(columns=['nParticles'], inplace=True)\n",
    "\n",
    "    bg_df[\"label\"] = 0  # Assign label 0 for background events\n",
    "\n",
    "    # Extract background type from filename (remove \"B\" and \".csv\")\n",
    "    bg_type = bg_file[1:].replace(\".csv\", \"\")\n",
    "    bg_df[\"background_type\"] = bg_type  # Store background type\n",
    "\n",
    "    background_dfs.append(bg_df)\n",
    "    background_labels.append(bg_file)  # Store file name for reference\n",
    "    background_types.append(bg_type)\n",
    "\n",
    "# Drop 'background_type' column before extracting features\n",
    "X_signal = signal_df.drop(columns=[\"label\"], errors=\"ignore\")  # Ensure label is dropped\n",
    "y_signal = signal_df[\"label\"]  # Extract labels\n",
    "\n",
    "X_backgrounds = [bg.drop(columns=[\"label\", \"background_type\"], errors=\"ignore\") for bg in background_dfs]  # Drop extra columns\n",
    "y_backgrounds = [bg[\"label\"] for bg in background_dfs]  # Extract labels correctly\n",
    "\n",
    "# # Extract features (X) and labels (y)\n",
    "# X_signal = signal_df.iloc[:, :-1]  # Features for signal\n",
    "# y_signal = signal_df.iloc[:, -1]   # Labels for signal\n",
    "\n",
    "# X_backgrounds = [bg.iloc[:, :-1] for bg in background_dfs]  # Features for each background dataset\n",
    "# y_backgrounds = [bg.iloc[:, -1] for bg in background_dfs]  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved splits for background 0: BWW.csv\n",
      "Saved splits for background 1: BZH.csv\n",
      "Saved splits for background 2: BZZ.csv\n",
      "Saved splits for background 3: Bpebb.csv\n",
      "Saved splits for background 4: Bpebbqq.csv\n",
      "Saved splits for background 5: BpeqqH.csv\n",
      "Saved splits for background 6: Bpett.csv\n",
      "Saved splits for background 7: Bqq.csv\n",
      "Saved splits for background 8: BqqHX.csv\n",
      "Saved splits for background 9: BqqX.csv\n",
      "Saved splits for background 10: BqqqqX.csv\n",
      "Saved splits for background 11: Btt.csv\n",
      "All dataset splits have been saved!\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to store the split datasets\n",
    "os.makedirs('split_datasets', exist_ok=True)\n",
    "\n",
    "# First, create a consistent three-way split for the signal dataset\n",
    "X_train_val_signal, X_test_signal, y_train_val_signal, y_test_signal = train_test_split(\n",
    "    X_signal, y_signal, test_size=test_size, random_state=42, stratify=y_signal\n",
    ")\n",
    "\n",
    "X_train_signal, X_val_signal, y_train_signal, y_val_signal = train_test_split(\n",
    "    X_train_val_signal, y_train_val_signal, test_size=0.2, random_state=42, stratify=y_train_val_signal\n",
    ")\n",
    "\n",
    "# Save signal splits\n",
    "joblib.dump(X_train_signal, 'split_datasets/X_train_signal.pkl')\n",
    "joblib.dump(X_val_signal, 'split_datasets/X_val_signal.pkl')\n",
    "joblib.dump(X_test_signal, 'split_datasets/X_test_signal.pkl')\n",
    "joblib.dump(y_train_signal, 'split_datasets/y_train_signal.pkl')\n",
    "joblib.dump(y_val_signal, 'split_datasets/y_val_signal.pkl')\n",
    "joblib.dump(y_test_signal, 'split_datasets/y_test_signal.pkl')\n",
    "\n",
    "# Prepare to store test background types\n",
    "background_types_train = []\n",
    "background_types_val = []\n",
    "background_types_test = []\n",
    "\n",
    "# Split and save each background dataset\n",
    "for i, bg_label in enumerate(background_labels):\n",
    "    clean_name = bg_label.replace('.csv', '').replace(' ', '_')\n",
    "\n",
    "    X_bg = X_backgrounds[i]\n",
    "    y_bg = y_backgrounds[i]\n",
    "\n",
    "    X_train_val_bg, X_test_bg, y_train_val_bg, y_test_bg = train_test_split(\n",
    "        X_bg, y_bg, test_size=test_size, random_state=42, stratify=y_bg\n",
    "    )\n",
    "\n",
    "    X_train_bg, X_val_bg, y_train_bg, y_val_bg = train_test_split(\n",
    "        X_train_val_bg, y_train_val_bg, test_size=0.2, random_state=42, stratify=y_train_val_bg\n",
    "    )\n",
    "\n",
    "    # Store background types for test set\n",
    "    background_types_train.extend([background_labels[i][1:].replace(\".csv\", \"\")] * len(X_train_bg))\n",
    "    background_types_val.extend([background_labels[i][1:].replace(\".csv\", \"\")] * len(X_val_bg))\n",
    "    background_types_test.extend([background_labels[i][1:].replace(\".csv\", \"\")] * len(X_test_bg))\n",
    "\n",
    "    # Save background splits\n",
    "    joblib.dump(X_train_bg, f'split_datasets/X_train_{clean_name}.pkl')\n",
    "    joblib.dump(X_val_bg, f'split_datasets/X_val_{clean_name}.pkl')\n",
    "    joblib.dump(X_test_bg, f'split_datasets/X_test_{clean_name}.pkl')\n",
    "    joblib.dump(y_train_bg, f'split_datasets/y_train_{clean_name}.pkl')\n",
    "    joblib.dump(y_val_bg, f'split_datasets/y_val_{clean_name}.pkl')\n",
    "    joblib.dump(y_test_bg, f'split_datasets/y_test_{clean_name}.pkl')\n",
    "\n",
    "    print(f\"Saved splits for background {i}: {bg_label}\")\n",
    "\n",
    "# Save background types for the test set\n",
    "joblib.dump(background_types_train, 'split_datasets/background_types_train.pkl')\n",
    "joblib.dump(background_types_val, 'split_datasets/background_types_val.pkl')\n",
    "joblib.dump(background_types_test, 'split_datasets/background_types_test.pkl')\n",
    "\n",
    "print(\"All dataset splits have been saved!\")\n",
    "\n",
    "# # Split and save each background dataset\n",
    "# for i, bg_label in enumerate(background_labels):\n",
    "#     # Get clean filename for saving\n",
    "#     clean_name = bg_label.replace('.csv', '').replace(' ', '_')\n",
    "    \n",
    "#     X_bg = X_backgrounds[i]\n",
    "#     y_bg = y_backgrounds[i]\n",
    "    \n",
    "#     X_train_val_bg, X_test_bg, y_train_val_bg, y_test_bg = train_test_split(\n",
    "#         X_bg, y_bg, test_size=0.25, random_state=42, stratify=y_bg\n",
    "#     )\n",
    "    \n",
    "#     X_train_bg, X_val_bg, y_train_bg, y_val_bg = train_test_split(\n",
    "#         X_train_val_bg, y_train_val_bg, test_size=0.2, random_state=42, stratify=y_train_val_bg\n",
    "#     )\n",
    "    \n",
    "#     # Save background splits\n",
    "#     joblib.dump(X_train_bg, f'split_datasets/X_train_{clean_name}.pkl')\n",
    "#     joblib.dump(X_val_bg, f'split_datasets/X_val_{clean_name}.pkl')\n",
    "#     joblib.dump(X_test_bg, f'split_datasets/X_test_{clean_name}.pkl')\n",
    "#     joblib.dump(y_train_bg, f'split_datasets/y_train_{clean_name}.pkl')\n",
    "#     joblib.dump(y_val_bg, f'split_datasets/y_val_{clean_name}.pkl')\n",
    "#     joblib.dump(y_test_bg, f'split_datasets/y_test_{clean_name}.pkl')\n",
    "    \n",
    "#     print(f\"Saved splits for background {i}: {bg_label}\")\n",
    "\n",
    "# print(\"All dataset splits have been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting BDT Training...\n",
      "\n",
      "\n",
      "Starting BDT Training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b0ac19624e4d59a7303105299ccac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/12 [00:00<?, ?model/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 1/12 trained on BWW.csv (Time: 166.74 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 2/12 trained on BZH.csv (Time: 257.60 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 3/12 trained on BZZ.csv (Time: 2967.88 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 4/12 trained on Bpebb.csv (Time: 216.72 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 5/12 trained on Bpebbqq.csv (Time: 233.46 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 6/12 trained on BpeqqH.csv (Time: 252.57 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 7/12 trained on Bpett.csv (Time: 181.97 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 8/12 trained on Bqq.csv (Time: 288.71 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 9/12 trained on BqqHX.csv (Time: 317.38 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 10/12 trained on BqqX.csv (Time: 178.74 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 11/12 trained on BqqqqX.csv (Time: 165.68 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagishinnosuke/Documents/2024-2025 Stanford/CS229/Final Project/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model 12/12 trained on Btt.csv (Time: 207.63 sec)\n",
      "\n",
      "✅ Training Complete! All models are ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train simple BTD models\n",
    "# Store trained models and test sets\n",
    "trained_models = []\n",
    "train_test_splits = []\n",
    "\n",
    "depth = 2\n",
    "n = 100\n",
    "lr = 0.1\n",
    "\n",
    "print(\"\\nStarting BDT Training...\\n\")\n",
    "\n",
    "# Train simple BDT models\n",
    "# Store trained models\n",
    "trained_models = []\n",
    "\n",
    "depth = 2\n",
    "n = 100\n",
    "lr = 0.1\n",
    "\n",
    "print(\"\\nStarting BDT Training...\\n\")\n",
    "\n",
    "# Load signal training data\n",
    "X_train_signal = joblib.load('split_datasets/X_train_signal.pkl')\n",
    "y_train_signal = joblib.load('split_datasets/y_train_signal.pkl')\n",
    "\n",
    "# Initialize progress bar correctly in Jupyter\n",
    "with tqdm(total=12, desc=\"Training Progress\", unit=\"model\", leave=True) as pbar:\n",
    "    for i in range(12):\n",
    "        start_time = time.time()  # Track time for each model\n",
    "\n",
    "        # Clean filename for loading\n",
    "        clean_name = background_labels[i].replace('.csv', '').replace(' ', '_')\n",
    "        \n",
    "        # Load background training data\n",
    "        X_train_bg = joblib.load(f'split_datasets/X_train_{clean_name}.pkl')\n",
    "        y_train_bg = joblib.load(f'split_datasets/y_train_{clean_name}.pkl')\n",
    "        \n",
    "        # Combine signal + one background dataset for training\n",
    "        X_train_combined = pd.concat([X_train_signal, X_train_bg])\n",
    "        y_train_combined = np.concatenate([y_train_signal, y_train_bg])\n",
    "\n",
    "        # Train a Boosted Decision Tree (BDT)\n",
    "        bdt = AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=depth),  \n",
    "            n_estimators=n, \n",
    "            learning_rate=lr,\n",
    "            algorithm=\"SAMME\"\n",
    "        )\n",
    "\n",
    "        bdt.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "        # Store trained model\n",
    "        trained_models.append(bdt)\n",
    "\n",
    "        # Use `tqdm.write()` instead of `print()`\n",
    "        elapsed_time = time.time() - start_time\n",
    "        tqdm.write(f\"✔ Model {i+1}/12 trained on {background_labels[i]} (Time: {elapsed_time:.2f} sec)\")\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "tqdm.write(\"\\n✅ Training Complete! All models are ready.\\n\")\n",
    "\n",
    "# # Initialize progress bar correctly in Jupyter\n",
    "# with tqdm(total=12, desc=\"Training Progress\", unit=\"model\", leave=True) as pbar:\n",
    "#     for i in range(12):\n",
    "#         start_time = time.time()  # Track time for each model\n",
    "\n",
    "#         # Combine signal + one background dataset\n",
    "#         X_combined = pd.concat([X_signal, X_backgrounds[i]])\n",
    "#         y_combined = np.concatenate([y_signal, y_backgrounds[i]])\n",
    "\n",
    "#         # Split into train (75%) and test (25%)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.25, random_state=42)\n",
    "\n",
    "#         # Train a Boosted Decision Tree (BDT)\n",
    "#         bdt = AdaBoostClassifier(\n",
    "#             estimator=DecisionTreeClassifier(max_depth=depth),  \n",
    "#             n_estimators=n, \n",
    "#             learning_rate=lr,\n",
    "#             algorithm=\"SAMME\"\n",
    "#         )\n",
    "\n",
    "#         bdt.fit(X_train, y_train)\n",
    "\n",
    "#         # Store trained model and test data\n",
    "#         trained_models.append(bdt)\n",
    "#         train_test_splits.append((X_test, y_test))\n",
    "\n",
    "#         # Use `tqdm.write()` instead of `print()`\n",
    "#         elapsed_time = time.time() - start_time\n",
    "#         tqdm.write(f\"✔ Model {i+1}/12 trained on {background_labels[i]} (Time: {elapsed_time:.2f} sec)\")\n",
    "\n",
    "#         # Update progress bar\n",
    "#         pbar.update(1)\n",
    "\n",
    "# tqdm.write(\"\\n✅ Training Complete! All models are ready.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 saved to models/bdt_model_bg1_depth2_n100_lr0.1.joblib\n",
      "Model 2 saved to models/bdt_model_bg2_depth2_n100_lr0.1.joblib\n",
      "Model 3 saved to models/bdt_model_bg3_depth2_n100_lr0.1.joblib\n",
      "Model 4 saved to models/bdt_model_bg4_depth2_n100_lr0.1.joblib\n",
      "Model 5 saved to models/bdt_model_bg5_depth2_n100_lr0.1.joblib\n",
      "Model 6 saved to models/bdt_model_bg6_depth2_n100_lr0.1.joblib\n",
      "Model 7 saved to models/bdt_model_bg7_depth2_n100_lr0.1.joblib\n",
      "Model 8 saved to models/bdt_model_bg8_depth2_n100_lr0.1.joblib\n",
      "Model 9 saved to models/bdt_model_bg9_depth2_n100_lr0.1.joblib\n",
      "Model 10 saved to models/bdt_model_bg10_depth2_n100_lr0.1.joblib\n",
      "Model 11 saved to models/bdt_model_bg11_depth2_n100_lr0.1.joblib\n",
      "Model 12 saved to models/bdt_model_bg12_depth2_n100_lr0.1.joblib\n"
     ]
    }
   ],
   "source": [
    "# Define the folder to save models\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Save each trained model with detailed filename\n",
    "for i, model in enumerate(trained_models):\n",
    "    filename = f\"bdt_model_bg{i+1}_depth{depth}_n{n}_lr{lr}.joblib\"\n",
    "    filepath = os.path.join(model_dir, filename)\n",
    "    joblib.dump(model, filepath)\n",
    "    print(f\"Model {i+1} saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal Test</th>\n",
       "      <th>Background 1 Test</th>\n",
       "      <th>Background 2 Test</th>\n",
       "      <th>Background 3 Test</th>\n",
       "      <th>Background 4 Test</th>\n",
       "      <th>Background 5 Test</th>\n",
       "      <th>Background 6 Test</th>\n",
       "      <th>Background 7 Test</th>\n",
       "      <th>Background 8 Test</th>\n",
       "      <th>Background 9 Test</th>\n",
       "      <th>Background 10 Test</th>\n",
       "      <th>Background 11 Test</th>\n",
       "      <th>Background 12 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>0.830092</td>\n",
       "      <td>0.522488</td>\n",
       "      <td>0.789417</td>\n",
       "      <td>0.729303</td>\n",
       "      <td>0.664949</td>\n",
       "      <td>0.790988</td>\n",
       "      <td>0.826804</td>\n",
       "      <td>0.805323</td>\n",
       "      <td>0.557029</td>\n",
       "      <td>0.816805</td>\n",
       "      <td>0.657025</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>0.784022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>0.716942</td>\n",
       "      <td>0.450917</td>\n",
       "      <td>0.478177</td>\n",
       "      <td>0.438582</td>\n",
       "      <td>0.447671</td>\n",
       "      <td>0.554803</td>\n",
       "      <td>0.674140</td>\n",
       "      <td>0.661642</td>\n",
       "      <td>0.491773</td>\n",
       "      <td>0.666135</td>\n",
       "      <td>0.455183</td>\n",
       "      <td>0.580045</td>\n",
       "      <td>0.737439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.473946</td>\n",
       "      <td>0.618781</td>\n",
       "      <td>0.428758</td>\n",
       "      <td>0.433737</td>\n",
       "      <td>0.549142</td>\n",
       "      <td>0.658349</td>\n",
       "      <td>0.672656</td>\n",
       "      <td>0.511647</td>\n",
       "      <td>0.649224</td>\n",
       "      <td>0.432573</td>\n",
       "      <td>0.581949</td>\n",
       "      <td>0.805927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 4</th>\n",
       "      <td>0.783884</td>\n",
       "      <td>0.583464</td>\n",
       "      <td>0.718744</td>\n",
       "      <td>0.618569</td>\n",
       "      <td>0.316660</td>\n",
       "      <td>0.603033</td>\n",
       "      <td>0.659444</td>\n",
       "      <td>0.663665</td>\n",
       "      <td>0.557060</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.346506</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>0.795954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 5</th>\n",
       "      <td>0.757006</td>\n",
       "      <td>0.589360</td>\n",
       "      <td>0.672788</td>\n",
       "      <td>0.572893</td>\n",
       "      <td>0.458409</td>\n",
       "      <td>0.407339</td>\n",
       "      <td>0.473991</td>\n",
       "      <td>0.570513</td>\n",
       "      <td>0.616500</td>\n",
       "      <td>0.588306</td>\n",
       "      <td>0.524924</td>\n",
       "      <td>0.570369</td>\n",
       "      <td>0.757428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 6</th>\n",
       "      <td>0.731884</td>\n",
       "      <td>0.596802</td>\n",
       "      <td>0.669612</td>\n",
       "      <td>0.595648</td>\n",
       "      <td>0.454242</td>\n",
       "      <td>0.397495</td>\n",
       "      <td>0.410166</td>\n",
       "      <td>0.524707</td>\n",
       "      <td>0.631354</td>\n",
       "      <td>0.560646</td>\n",
       "      <td>0.535347</td>\n",
       "      <td>0.572344</td>\n",
       "      <td>0.729097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 7</th>\n",
       "      <td>0.789843</td>\n",
       "      <td>0.743163</td>\n",
       "      <td>0.775685</td>\n",
       "      <td>0.766907</td>\n",
       "      <td>0.740535</td>\n",
       "      <td>0.733954</td>\n",
       "      <td>0.734542</td>\n",
       "      <td>0.562559</td>\n",
       "      <td>0.761066</td>\n",
       "      <td>0.730211</td>\n",
       "      <td>0.760102</td>\n",
       "      <td>0.720166</td>\n",
       "      <td>0.635722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 8</th>\n",
       "      <td>0.753819</td>\n",
       "      <td>0.358388</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.624582</td>\n",
       "      <td>0.443739</td>\n",
       "      <td>0.716683</td>\n",
       "      <td>0.758758</td>\n",
       "      <td>0.701672</td>\n",
       "      <td>0.293732</td>\n",
       "      <td>0.737114</td>\n",
       "      <td>0.424522</td>\n",
       "      <td>0.700906</td>\n",
       "      <td>0.455015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 9</th>\n",
       "      <td>0.678968</td>\n",
       "      <td>0.608082</td>\n",
       "      <td>0.654303</td>\n",
       "      <td>0.559328</td>\n",
       "      <td>0.447581</td>\n",
       "      <td>0.376136</td>\n",
       "      <td>0.408135</td>\n",
       "      <td>0.501965</td>\n",
       "      <td>0.634333</td>\n",
       "      <td>0.405804</td>\n",
       "      <td>0.458886</td>\n",
       "      <td>0.422025</td>\n",
       "      <td>0.778306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 10</th>\n",
       "      <td>0.818564</td>\n",
       "      <td>0.636414</td>\n",
       "      <td>0.764232</td>\n",
       "      <td>0.687371</td>\n",
       "      <td>0.397175</td>\n",
       "      <td>0.723322</td>\n",
       "      <td>0.775027</td>\n",
       "      <td>0.759130</td>\n",
       "      <td>0.607725</td>\n",
       "      <td>0.762132</td>\n",
       "      <td>0.392722</td>\n",
       "      <td>0.725604</td>\n",
       "      <td>0.846210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 11</th>\n",
       "      <td>0.825084</td>\n",
       "      <td>0.775082</td>\n",
       "      <td>0.796037</td>\n",
       "      <td>0.748473</td>\n",
       "      <td>0.716971</td>\n",
       "      <td>0.711084</td>\n",
       "      <td>0.755369</td>\n",
       "      <td>0.724371</td>\n",
       "      <td>0.776836</td>\n",
       "      <td>0.742969</td>\n",
       "      <td>0.717411</td>\n",
       "      <td>0.718225</td>\n",
       "      <td>0.838026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 12</th>\n",
       "      <td>0.828113</td>\n",
       "      <td>0.736573</td>\n",
       "      <td>0.837692</td>\n",
       "      <td>0.846271</td>\n",
       "      <td>0.856717</td>\n",
       "      <td>0.841408</td>\n",
       "      <td>0.837900</td>\n",
       "      <td>0.791300</td>\n",
       "      <td>0.713972</td>\n",
       "      <td>0.836648</td>\n",
       "      <td>0.856097</td>\n",
       "      <td>0.838166</td>\n",
       "      <td>0.424579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Signal Test  Background 1 Test  Background 2 Test  \\\n",
       "Model 1      0.830092           0.522488           0.789417   \n",
       "Model 2      0.716942           0.450917           0.478177   \n",
       "Model 3      0.758447           0.473946           0.618781   \n",
       "Model 4      0.783884           0.583464           0.718744   \n",
       "Model 5      0.757006           0.589360           0.672788   \n",
       "Model 6      0.731884           0.596802           0.669612   \n",
       "Model 7      0.789843           0.743163           0.775685   \n",
       "Model 8      0.753819           0.358388           0.700176   \n",
       "Model 9      0.678968           0.608082           0.654303   \n",
       "Model 10     0.818564           0.636414           0.764232   \n",
       "Model 11     0.825084           0.775082           0.796037   \n",
       "Model 12     0.828113           0.736573           0.837692   \n",
       "\n",
       "          Background 3 Test  Background 4 Test  Background 5 Test  \\\n",
       "Model 1            0.729303           0.664949           0.790988   \n",
       "Model 2            0.438582           0.447671           0.554803   \n",
       "Model 3            0.428758           0.433737           0.549142   \n",
       "Model 4            0.618569           0.316660           0.603033   \n",
       "Model 5            0.572893           0.458409           0.407339   \n",
       "Model 6            0.595648           0.454242           0.397495   \n",
       "Model 7            0.766907           0.740535           0.733954   \n",
       "Model 8            0.624582           0.443739           0.716683   \n",
       "Model 9            0.559328           0.447581           0.376136   \n",
       "Model 10           0.687371           0.397175           0.723322   \n",
       "Model 11           0.748473           0.716971           0.711084   \n",
       "Model 12           0.846271           0.856717           0.841408   \n",
       "\n",
       "          Background 6 Test  Background 7 Test  Background 8 Test  \\\n",
       "Model 1            0.826804           0.805323           0.557029   \n",
       "Model 2            0.674140           0.661642           0.491773   \n",
       "Model 3            0.658349           0.672656           0.511647   \n",
       "Model 4            0.659444           0.663665           0.557060   \n",
       "Model 5            0.473991           0.570513           0.616500   \n",
       "Model 6            0.410166           0.524707           0.631354   \n",
       "Model 7            0.734542           0.562559           0.761066   \n",
       "Model 8            0.758758           0.701672           0.293732   \n",
       "Model 9            0.408135           0.501965           0.634333   \n",
       "Model 10           0.775027           0.759130           0.607725   \n",
       "Model 11           0.755369           0.724371           0.776836   \n",
       "Model 12           0.837900           0.791300           0.713972   \n",
       "\n",
       "          Background 9 Test  Background 10 Test  Background 11 Test  \\\n",
       "Model 1            0.816805            0.657025            0.786037   \n",
       "Model 2            0.666135            0.455183            0.580045   \n",
       "Model 3            0.649224            0.432573            0.581949   \n",
       "Model 4            0.686363            0.346506            0.655702   \n",
       "Model 5            0.588306            0.524924            0.570369   \n",
       "Model 6            0.560646            0.535347            0.572344   \n",
       "Model 7            0.730211            0.760102            0.720166   \n",
       "Model 8            0.737114            0.424522            0.700906   \n",
       "Model 9            0.405804            0.458886            0.422025   \n",
       "Model 10           0.762132            0.392722            0.725604   \n",
       "Model 11           0.742969            0.717411            0.718225   \n",
       "Model 12           0.836648            0.856097            0.838166   \n",
       "\n",
       "          Background 12 Test  \n",
       "Model 1             0.784022  \n",
       "Model 2             0.737439  \n",
       "Model 3             0.805927  \n",
       "Model 4             0.795954  \n",
       "Model 5             0.757428  \n",
       "Model 6             0.729097  \n",
       "Model 7             0.635722  \n",
       "Model 8             0.455015  \n",
       "Model 9             0.778306  \n",
       "Model 10            0.846210  \n",
       "Model 11            0.838026  \n",
       "Model 12            0.424579  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load signal test data\n",
    "X_test_signal = joblib.load('split_datasets/X_test_signal.pkl')\n",
    "y_test_signal = joblib.load('split_datasets/y_test_signal.pkl')\n",
    "\n",
    "# Load background test datasets\n",
    "X_test_backgrounds = []\n",
    "y_test_backgrounds = []\n",
    "\n",
    "for bg_file in background_labels:\n",
    "    clean_name = bg_file.replace('.csv', '').replace(' ', '_')\n",
    "    X_test_bg = joblib.load(f'split_datasets/X_test_{clean_name}.pkl')\n",
    "    y_test_bg = joblib.load(f'split_datasets/y_test_{clean_name}.pkl')\n",
    "    \n",
    "    X_test_backgrounds.append(X_test_bg)\n",
    "    y_test_backgrounds.append(y_test_bg)\n",
    "\n",
    "# Initialize a 12x13 matrix to store results\n",
    "output_matrix = np.zeros((12, 13))\n",
    "\n",
    "# Evaluate each trained BDT model on the test datasets\n",
    "for model_idx, model in enumerate(trained_models):\n",
    "    for dataset_idx, dataset in enumerate([X_test_signal] + X_test_backgrounds):  \n",
    "        # Get predicted probability of being signal\n",
    "        predictions = model.predict_proba(dataset)[:, 1]  # Extract P(class=1) (signal probability)\n",
    "        \n",
    "        # Store the average probability of being signal on **test dataset only**\n",
    "        output_matrix[model_idx, dataset_idx] = np.mean(predictions)\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "datasets = [\"Signal Test\"] + [f\"Background {i+1} Test\" for i in range(12)]\n",
    "model_labels = [f\"Model {i+1}\" for i in range(12)]\n",
    "\n",
    "df_results = pd.DataFrame(output_matrix, index=model_labels, columns=datasets)\n",
    "\n",
    "df_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
